{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"markdown","source":"**Импорты библиотек:**","metadata":{}},{"cell_type":"code","source":"!pip install -q tqdm==4.66.5\n!pip install -q torch==2.4.1+cu121\n!pip install -q torchvision==0.19.1+cu121\n!pip install -q transformers==4.44.2\n!pip install -q comet_ml==3.47.6\n!pip install -q triton==3.1.0\n!pip install -q torchattacks==3.5.1\n!pip install -q jax==0.4.38\n!pip install -q jaxlib==0.4.38\n!pip install -q torchlars==0.1.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:36:30.325527Z","iopub.execute_input":"2024-12-29T22:36:30.325727Z","iopub.status.idle":"2024-12-29T22:38:49.952212Z","shell.execute_reply.started":"2024-12-29T22:36:30.325708Z","shell.execute_reply":"2024-12-29T22:38:49.951101Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m710.6/710.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.3/980.3 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 1.17.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\ndatasets 3.2.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\ndistributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\ndocker 7.1.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ngoogle-cloud-bigtable 2.26.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.25.1 which is incompatible.\ngoogle-genai 0.3.0 requires requests<3.0.0dev,>=2.28.1, but you have requests 2.25.1 which is incompatible.\njupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\nlibpysal 4.9.2 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntiktoken 0.8.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ntweepy 4.14.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\nyfinance 0.2.43 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for torchlars (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nimport os\n\nimport comet_ml\n\nimport torch\nimport torchvision\nfrom torchvision.transforms import v2\nimport torchattacks\nfrom torchlars import LARS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:04.485805Z","iopub.execute_input":"2024-12-29T22:39:04.486180Z","iopub.status.idle":"2024-12-29T22:39:08.752275Z","shell.execute_reply.started":"2024-12-29T22:39:04.486147Z","shell.execute_reply":"2024-12-29T22:39:08.751576Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Utils:**","metadata":{}},{"cell_type":"markdown","source":"**Функция для фиксирования сида:**","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:11.044979Z","iopub.execute_input":"2024-12-29T22:39:11.045548Z","iopub.status.idle":"2024-12-29T22:39:11.049512Z","shell.execute_reply.started":"2024-12-29T22:39:11.045521Z","shell.execute_reply":"2024-12-29T22:39:11.048731Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Additional utils:**","metadata":{}},{"cell_type":"code","source":"def get_root(env):\n    # supports env == \"colab\", env == \"kaggle\"\n    if env == \"kaggle\":\n        return \"/kaggle/working/\"\n    else:\n        return \"./\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:13.293084Z","iopub.execute_input":"2024-12-29T22:39:13.293379Z","iopub.status.idle":"2024-12-29T22:39:13.297576Z","shell.execute_reply.started":"2024-12-29T22:39:13.293356Z","shell.execute_reply":"2024-12-29T22:39:13.296636Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# this augmentation first converts PIL image to Tensor,\n# then casts resulting tensor to type=torch.float32,\n# finally normalizes the image\n\ndefault_aug = v2.Compose([v2.PILToTensor(),\n                          v2.ToDtype(torch.float32, scale=True),\n                          v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:15.424605Z","iopub.execute_input":"2024-12-29T22:39:15.424926Z","iopub.status.idle":"2024-12-29T22:39:15.429452Z","shell.execute_reply.started":"2024-12-29T22:39:15.424898Z","shell.execute_reply":"2024-12-29T22:39:15.428553Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# This function is used later in DataLoaders to fix the seed setting bugs when using several workers\n\ndef worker_init_fn(worker_id):\n    torch_seed = torch.initial_seed() % (2**32)\n    random.seed(torch_seed)\n    np.random.seed(torch_seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:17.352534Z","iopub.execute_input":"2024-12-29T22:39:17.352872Z","iopub.status.idle":"2024-12-29T22:39:17.356935Z","shell.execute_reply.started":"2024-12-29T22:39:17.352842Z","shell.execute_reply":"2024-12-29T22:39:17.356077Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"**Датасет + DataLoaders:**","metadata":{}},{"cell_type":"code","source":"def get_CIFAR10_data(train_transform=default_aug, test_transform=default_aug, env=\"colab\"):\n    root = get_root(env)\n    data_train = torchvision.datasets.CIFAR10(root=root, train=True, transform=train_transform, download=True)\n    print(\"Prepare Train Set: ✅\")\n    data_test = torchvision.datasets.CIFAR10(root=root, train=False, transform=test_transform)\n    print(\"Prepare Test Set:  ✅\")\n    return data_train, data_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:19.284866Z","iopub.execute_input":"2024-12-29T22:39:19.285209Z","iopub.status.idle":"2024-12-29T22:39:19.289665Z","shell.execute_reply.started":"2024-12-29T22:39:19.285181Z","shell.execute_reply":"2024-12-29T22:39:19.288707Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def get_CIFAR10_dataloaders(batch_size, train_transform=default_aug, test_transform=default_aug, env=\"colab\"):\n    root = get_root(env)\n    data_train = torchvision.datasets.CIFAR10(root=root, train=True, transform=train_transform, download=True)\n    dataloader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n    print(\"Prepare Train Set: ✅\")\n    data_test = torchvision.datasets.CIFAR10(root=root, train=False, transform=test_transform)\n    dataloader_test = torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn)\n    print(\"Prepare Test Set:  ✅\")\n    return dataloader_train, dataloader_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:20.945329Z","iopub.execute_input":"2024-12-29T22:39:20.945642Z","iopub.status.idle":"2024-12-29T22:39:20.950940Z","shell.execute_reply.started":"2024-12-29T22:39:20.945614Z","shell.execute_reply":"2024-12-29T22:39:20.950282Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"**Код цикла предобучения/дообучения SSL-метода:**","metadata":{}},{"cell_type":"code","source":"class ViewGenerator(object):\n    # Take several copies of one image and apply a transform to them\n    def __init__(self, transform, n_views=2):\n        self.transform = transform\n        self.n_views = n_views\n        \n    def __call__(self, x):\n        return [self.transform(x) for i in range(self.n_views)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:22.905435Z","iopub.execute_input":"2024-12-29T22:39:22.905827Z","iopub.status.idle":"2024-12-29T22:39:22.911410Z","shell.execute_reply.started":"2024-12-29T22:39:22.905795Z","shell.execute_reply":"2024-12-29T22:39:22.910367Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def get_CIFAR10_contrastive_dataloaders(batch_size, transform=default_aug, env=\"colab\"):\n    root = get_root(env)\n    data = torchvision.datasets.CIFAR10(root=root,\n                                        train=True, \n                                        transform=ViewGenerator(transform=transform, n_views=2),\n                                        download=True)\n    dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n    print(\"Prepare Set: ✅\")\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:24.985269Z","iopub.execute_input":"2024-12-29T22:39:24.985649Z","iopub.status.idle":"2024-12-29T22:39:24.990495Z","shell.execute_reply.started":"2024-12-29T22:39:24.985625Z","shell.execute_reply":"2024-12-29T22:39:24.989492Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class SimCLR(torch.nn.Module):\n    def __init__(self, encoder, head_out_dim, head_hidden_dim, enc_out_dim=512):\n        super(SimCLR, self).__init__()\n        self.encoder = encoder\n        # MLP projection head (authors of SimCLR show that it is better to use MLP rather than simple Linear layer as a head)\n        self.head = torch.nn.Sequential(\n            torch.nn.Linear(enc_out_dim, head_hidden_dim),\n            torch.nn.ReLU(),\n            torch.nn.Linear(head_hidden_dim, head_out_dim)\n        )\n\n    def forward(self, x):\n        enc_features = self.encoder(x)\n        logits = self.head(enc_features)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:27.313530Z","iopub.execute_input":"2024-12-29T22:39:27.313817Z","iopub.status.idle":"2024-12-29T22:39:27.318666Z","shell.execute_reply.started":"2024-12-29T22:39:27.313797Z","shell.execute_reply":"2024-12-29T22:39:27.317861Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def InfoNCE_loss(logits, temperature=0.2):\n    cosine_sim = torch.nn.functional.cosine_similarity(torch.unsqueeze(logits, dim=1), torch.unsqueeze(logits, dim=0), dim=-1)\n    \n    # Mask out cosine similarity to itself\n    mask = torch.eye(cosine_sim.shape[0], dtype=torch.bool, device=logits.device)\n    cosine_sim.masked_fill_(mask, -torch.inf)\n    \n    # Find positive example - it is (batch_size / 2) positions away from the original example\n    positive_mask = mask.roll(shifts=cosine_sim.shape[0] // 2, dims=0)\n    \n    # InfoNCE loss\n    cosine_sim = cosine_sim / temperature\n    loss = -cosine_sim[positive_mask] + torch.logsumexp(cosine_sim, dim=-1)\n    loss = loss.mean()\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:29.873267Z","iopub.execute_input":"2024-12-29T22:39:29.873587Z","iopub.status.idle":"2024-12-29T22:39:29.879508Z","shell.execute_reply.started":"2024-12-29T22:39:29.873565Z","shell.execute_reply":"2024-12-29T22:39:29.878553Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def pretrain_epoch(model, optimizer, loader, scaler, epoch, exp):\n    step = (epoch - 1) * len(loader)\n\n    model.train()\n\n    for batch_idx, (data, _) in enumerate(tqdm(loader)):\n        data = torch.cat(data, dim=0)\n        data = data.to(device)\n\n        optimizer.zero_grad()\n\n        with torch.autocast(\"cuda\", dtype=torch.float16, enabled=True):\n            logits = model(data)\n            loss = InfoNCE_loss(logits)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        if exp is not None:\n            exp.log_metrics({\"train loss (by steps)\": loss.item()}, step=(step + batch_idx))\n\n    return scaler\n\n\ndef pretrain(model, exp_name, optimizer, epochs, pretrain_loader, warmup_scheduler=None, scheduler=None, warmup_epochs=0, exp=None, env=\"colab\"):\n    scaler = torch.GradScaler(\"cuda\")\n    \n    for epoch in range(1, epochs + 1):\n        print(f\"Epoch {epoch}:\\n\")\n        scaler = pretrain_epoch(model, optimizer, pretrain_loader, scaler, epoch, exp)\n        \n        if warmup_scheduler is not None and epoch <= warmup_epochs:\n            warmup_scheduler.step()\n            if epoch == warmup_epochs:\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(epochs - warmup_epochs), eta_min=1e-4)\n        else:\n            if scheduler is not None:\n                scheduler.step()\n\n    filepath = f\"{get_root(env)}weights_{exp_name}_epoch{epochs}.pth\"\n    torch.save(model.state_dict(), filepath)\n    print(\"Save State of the Best Model: ✅\")\n\n    if exp is not None:\n        exp.log_model(name=filepath[len(get_root(env)):-4],\n                      file_or_folder=filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:32.673590Z","iopub.execute_input":"2024-12-29T22:39:32.673895Z","iopub.status.idle":"2024-12-29T22:39:32.681649Z","shell.execute_reply.started":"2024-12-29T22:39:32.673870Z","shell.execute_reply":"2024-12-29T22:39:32.680730Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"comet_ml.login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:51:21.979079Z","iopub.execute_input":"2024-12-29T16:51:21.979378Z","iopub.status.idle":"2024-12-29T16:51:22.168972Z","shell.execute_reply.started":"2024-12-29T16:51:21.979356Z","shell.execute_reply":"2024-12-29T16:51:22.168282Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:37:48.118580Z","iopub.execute_input":"2024-12-29T16:37:48.119019Z","iopub.status.idle":"2024-12-29T16:37:48.169504Z","shell.execute_reply.started":"2024-12-29T16:37:48.118979Z","shell.execute_reply":"2024-12-29T16:37:48.168374Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"SimCLR_aug = v2.Compose([\n    v2.PILToTensor(),\n    v2.ToDtype(torch.uint8, scale=True),\n    v2.RandomResizedCrop(\n        size=(32, 32),\n        scale=(0.08, 1.0),\n        interpolation=torchvision.transforms.InterpolationMode.BICUBIC,\n        antialias=True),\n    v2.RandomApply(\n        torch.nn.ModuleList([\n            v2.ColorJitter(\n                brightness=(0.6, 1.4),\n                contrast=(0.6, 1.4),\n                saturation=(0.6, 1.4),\n                hue=(-0.1, 0.1)\n            )\n        ]),\n        p=0.8\n    ),\n    v2.RandomGrayscale(p=0.2),\n    v2.RandomApply(\n        torch.nn.ModuleList([\n            v2.GaussianBlur(kernel_size=3)\n        ]),\n        p=0.5\n    ),\n    v2.RandomHorizontalFlip(p=0.5),\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:37:50.144639Z","iopub.execute_input":"2024-12-29T16:37:50.144920Z","iopub.status.idle":"2024-12-29T16:37:50.220051Z","shell.execute_reply.started":"2024-12-29T16:37:50.144900Z","shell.execute_reply":"2024-12-29T16:37:50.219193Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"NUM_EPOCHS = 10\nNUM_WARMUP_EPOCHS = 2\nBATCH_SIZE = 256\nexp_name = \"SimCLR_Pretrain\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:37:53.014466Z","iopub.execute_input":"2024-12-29T16:37:53.014784Z","iopub.status.idle":"2024-12-29T16:37:53.018527Z","shell.execute_reply.started":"2024-12-29T16:37:53.014756Z","shell.execute_reply":"2024-12-29T16:37:53.017750Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# random seed\nseed_everything(0)\n\n# get data and batchify it\npretrain_loader = get_CIFAR10_contrastive_dataloaders(batch_size=BATCH_SIZE, transform=SimCLR_aug, env=\"colab\")\n\n# initialize encoder\nencoder = torchvision.models.resnet.resnet18()\nencoder.fc = torch.nn.Identity()\nencoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nencoder.maxpool = torch.nn.Identity()\ntorch.nn.init.kaiming_normal_(encoder.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\") # initialize conv1 weights the same way as all the other Conv2d weights in ResNet18\n\n# initialize model\nmodel = SimCLR(encoder=encoder, head_out_dim=256, head_hidden_dim=2048)\nmodel.to(device)\n\n# choose optimizer and scheduler (if needed)\nbase_optimizer = torch.optim.SGD(model.parameters(), lr=0.4, weight_decay=1e-4)\noptimizer = LARS(optimizer=base_optimizer, eps=1e-8, trust_coef=0.02)\n\nwarmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.33, total_iters=NUM_WARMUP_EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:37:56.220402Z","iopub.execute_input":"2024-12-29T16:37:56.220723Z","iopub.status.idle":"2024-12-29T16:38:01.026656Z","shell.execute_reply.started":"2024-12-29T16:37:56.220697Z","shell.execute_reply":"2024-12-29T16:38:01.026015Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:01<00:00, 102921845.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./cifar-10-python.tar.gz to ./\nPrepare Set: ✅\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"exp = comet_ml.Experiment(project_name=\"SSL_Adversarial1\")\nexp.set_name(exp_name)\n\npretrain(model, exp_name, optimizer, NUM_EPOCHS, pretrain_loader, warmup_scheduler=warmup_scheduler, scheduler=None, warmup_epochs=NUM_WARMUP_EPOCHS, exp=exp, env=\"colab\")\n\nexp.end()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:38:05.792784Z","iopub.execute_input":"2024-12-29T16:38:05.793124Z","iopub.status.idle":"2024-12-29T16:50:34.646880Z","shell.execute_reply.started":"2024-12-29T16:38:05.793099Z","shell.execute_reply":"2024-12-29T16:50:34.646134Z"}},"outputs":[{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/askoro/ssl-adversarial1/6957af7f9f9d4667a2844337a9b0363f\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1:\n\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/196 [00:00<?, ?it/s]\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n/usr/local/lib/python3.10/dist-packages/torchlars/lars.py:140: UserWarning: This overload of add_ is deprecated:\n\tadd_(Number alpha, Tensor other)\nConsider using one of the following signatures instead:\n\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n  p.grad.add_(weight_decay, p.data)\n100%|██████████| 196/196 [01:15<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:13<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:14<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:13<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:13<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:13<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:14<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:14<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:14<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 196/196 [01:14<00:00,  2.65it/s]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : SimCLR_Pretrain\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/askoro/ssl-adversarial1/6957af7f9f9d4667a2844337a9b0363f\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [196]                   : (106301.21875, 403316.96875)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss (by steps) [1960] : (2.174712896347046, 6.18222188949585)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : SimCLR_Pretrain\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (48.69 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","output_type":"stream"},{"name":"stdout","text":"Save State of the Best Model: ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 33 metrics, params and output messages\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 17.19 MB/48.69 MB\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"**Код для обычного/adversarial Fine-Tuning'а (на одном GPU):**","metadata":{}},{"cell_type":"code","source":"def eval_epoch(model, loader, attack=None):\n    val_loss = 0.\n    val_acc = 0.\n\n    model.eval()\n\n    for data, target in tqdm(loader):\n        data = data.to(device)\n        target = target.to(device)\n\n        if attack is not None:\n            # perform adversarial attack\n            with torch.enable_grad():\n                data = attack(data, target)\n        \n        logits = model(data)\n        loss = torch.nn.functional.cross_entropy(logits, target)\n\n        val_loss += (loss.item() * data.shape[0])\n        val_acc += (torch.argmax(logits, dim=1) == target).sum().item()\n\n    val_loss /= len(loader.dataset)\n    val_acc /= len(loader.dataset)\n    return val_loss, val_acc\n\n\ndef train_epoch(model, optimizer, loader, scaler, epoch, exp, is_attack_used=False):\n    train_loss = 0.\n    train_acc = 0.\n\n    step = (epoch - 1) * len(loader)\n\n    model.train()\n\n    for batch_idx, (data, target) in enumerate(tqdm(loader)):\n        data = data.to(device)\n        target = target.to(device)\n\n        if is_attack_used != \"no\":\n            if is_attack_used == \"BIM\":\n                attack = torchattacks.BIM(model, eps=(4 / 255), alpha=(2 / 255), steps=5)\n            else:\n                attack = torchattacks.PGD(model, eps=(4 / 255), alpha=(2 / 255), steps=5)\n            # perform adversarial attack\n            data = attack(data, target)\n\n        optimizer.zero_grad()\n\n        with torch.autocast(\"cuda\", dtype=torch.float16, enabled=True):\n            logits = model(data)\n            loss = torch.nn.functional.cross_entropy(logits, target)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        with torch.no_grad():\n            train_loss += loss.item() * data.shape[0]\n            train_acc += (torch.argmax(logits, dim=1) == target).sum().item()\n\n        if exp is not None:\n            exp.log_metrics({\"train loss (by steps)\": loss.item()}, step=(step + batch_idx))\n\n    train_loss /= len(loader.dataset)\n    train_acc /= len(loader.dataset)\n    return train_loss, train_acc, scaler\n\n\ndef train(model, exp_name, optimizer, epochs, train_loader, val_loader, is_train_attack_used=\"no\", scheduler=None, exp=None, env=\"colab\"):\n    best_val_acc = 0.\n    best_val_acc_epoch = None\n    best_model_state_filepath = None\n\n    val_attacks_names = [\"No Attack\"]\n\n    scaler = torch.GradScaler(\"cuda\")\n\n    for epoch in range(1, epochs + 1):\n        print(f\"Epoch {epoch}:\\n\")\n        metrics = dict()\n        \n        train_loss, train_acc, scaler = train_epoch(model, optimizer, train_loader, scaler, epoch, exp, is_attack_used=is_train_attack_used)\n\n        val_attacks = [None]\n        \n        for it in range(len(val_attacks)):\n            val_loss, val_acc = eval_epoch(model, val_loader, attack=val_attacks[it])\n            metrics[val_attacks_names[it]] = {\"Loss\": val_loss, \"Accuracy\": val_acc}\n\n        if scheduler is not None:\n            scheduler.step()\n\n        print(\"\\n\")\n        print(\" Train:\")\n        print(f\"  Loss: {train_loss}, Accuracy: {train_acc}\")\n        print(\" Validation:\")\n        for it in metrics.items():\n            print(f\"  Loss: {it[1]['Loss']}, Accuracy: {it[1]['Accuracy']}\")\n\n\n        if exp is not None:\n            exp.log_metrics(\n                   {\"train loss\": train_loss,\n                    \"train accuracy\": train_acc},\n                    step=(epoch * len(train_loader)))\n            for it in metrics.items():\n                exp.log_metrics(\n                    {f\"validation loss ({it[0]})\": it[1]['Loss'],\n                     f\"validation accuracy ({it[0]})\": it[1]['Accuracy']},\n                     step=(epoch * len(train_loader)))\n\n        val_acc = metrics[\"No Attack\"][\"Accuracy\"]\n        \n        if val_acc > best_val_acc:\n            print(\"🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\")\n            best_val_acc = val_acc\n            best_val_acc_epoch = epoch\n            filepath = f\"{get_root(env)}best_weights_{exp_name}_epoch{best_val_acc_epoch}.pth\"\n            torch.save(model.state_dict(), filepath)\n            print(\"Save State of the Best Model: ✅\")\n            if best_model_state_filepath is not None:\n                os.remove(best_model_state_filepath)\n                print(\"Delete State File of the Previous Best Model: ✅\")\n            best_model_state_filepath = filepath\n\n        print('-----------------------------------------------------------------\\n')\n\n    if exp is not None:\n        exp.log_model(name=best_model_state_filepath[len(get_root(env)):-4],\n                      file_or_folder=best_model_state_filepath)\n\n\ndef test(model, loader, env=\"colab\"):\n    attacks_names = [\"No Attack\", \"i-FGSM\", \"PGD\", \"DI-FGSM\"]\n    \n    metrics = dict()\n\n    attacks = [None, \n               torchattacks.BIM(model, eps=(8 / 255), alpha=(2 / 255), steps=10),\n               torchattacks.PGD(model, eps=(8 / 255), alpha=(2 / 255), steps=10),\n               torchattacks.DIFGSM(model, eps=(8 / 255), alpha=(2 / 255), steps=10, resize_rate=0.9, diversity_prob=0.5)\n              ]\n    \n    for it in range(len(attacks)):\n        loss, acc = eval_epoch(model, loader, attack=attacks[it])\n        metrics[attacks_names[it]] = {\"Loss\": loss, \"Accuracy\": acc}\n\n    print(\"\\n\")\n    print(\"Final Metrics:\")\n    for it in metrics.items():\n        print(f\" {it[0]}:\")\n        print(f\"   Loss: {it[1]['Loss']}, Accuracy: {it[1]['Accuracy']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:45.776380Z","iopub.execute_input":"2024-12-29T22:39:45.776679Z","iopub.status.idle":"2024-12-29T22:39:45.793176Z","shell.execute_reply.started":"2024-12-29T22:39:45.776660Z","shell.execute_reply":"2024-12-29T22:39:45.792254Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Эксперименты","metadata":{}},{"cell_type":"markdown","source":"**Downstream-модель:**","metadata":{}},{"cell_type":"code","source":"class DownstreamModel(torch.nn.Module):\n    def __init__(self, encoder, head):\n        super(DownstreamModel, self).__init__()\n        self.encoder = encoder\n        self.head = head\n\n    def forward(self, x):\n        enc_features = self.encoder(x)\n        logits = self.head(enc_features)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:39:50.664769Z","iopub.execute_input":"2024-12-29T22:39:50.665053Z","iopub.status.idle":"2024-12-29T22:39:50.669503Z","shell.execute_reply.started":"2024-12-29T22:39:50.665031Z","shell.execute_reply":"2024-12-29T22:39:50.668732Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"**Берём энкодер из модели, прикрепляем линейную голову:**","metadata":{}},{"cell_type":"code","source":"seed_everything(0)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# initialize SimCLR encoder\nencoder = torchvision.models.resnet.resnet18()\nencoder.fc = torch.nn.Identity()\nencoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nencoder.maxpool = torch.nn.Identity()\ntorch.nn.init.kaiming_normal_(encoder.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\") # initialize conv1 weights the same way as all the other Conv2d weights in ResNet18\n\n# initialize SimCLR\nmodel = SimCLR(encoder=encoder, head_out_dim=256, head_hidden_dim=2048)\nmodel.to(device)\n\nmodel_state_dict = torch.load(\"./weights_SimCLR_Pretrain_epoch10.pth\", map_location=device, weights_only=False)\n\nmodel.load_state_dict(model_state_dict)\n\n# here I take only the backbone of the model and then use it as an encoder in a downstream model \nencoder = model.encoder\n\n# initialize new head\nNUM_CLASSES = 10 # there are 10 classes in CIFAR10\nHIDDEN_SIZE = 512 # output size of SimCLR encoder\n\nhead = torch.nn.Sequential(\n    torch.nn.Linear(HIDDEN_SIZE, 2 * HIDDEN_SIZE),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2 * HIDDEN_SIZE, NUM_CLASSES)\n)\n\n# create downstream model\nmodel = DownstreamModel(encoder=encoder, head=head)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:51:11.685593Z","iopub.execute_input":"2024-12-29T16:51:11.685927Z","iopub.status.idle":"2024-12-29T16:51:11.950448Z","shell.execute_reply.started":"2024-12-29T16:51:11.685897Z","shell.execute_reply":"2024-12-29T16:51:11.949494Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DownstreamModel(\n  (encoder): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): Identity()\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Identity()\n  )\n  (head): Sequential(\n    (0): Linear(in_features=512, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"**SimCLR (SFT):**","metadata":{}},{"cell_type":"code","source":"comet_ml.login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:51:15.759661Z","iopub.execute_input":"2024-12-29T16:51:15.760022Z","iopub.status.idle":"2024-12-29T16:51:15.987441Z","shell.execute_reply.started":"2024-12-29T16:51:15.759991Z","shell.execute_reply":"2024-12-29T16:51:15.986529Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# choose device for computing\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:51:29.596515Z","iopub.execute_input":"2024-12-29T16:51:29.596857Z","iopub.status.idle":"2024-12-29T16:51:29.600460Z","shell.execute_reply.started":"2024-12-29T16:51:29.596825Z","shell.execute_reply":"2024-12-29T16:51:29.599692Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"NUM_EPOCHS = 5\nBATCH_SIZE = 128\nexp_name = \"SimCLR_SFT\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:51:31.835403Z","iopub.execute_input":"2024-12-29T16:51:31.835680Z","iopub.status.idle":"2024-12-29T16:51:31.839258Z","shell.execute_reply.started":"2024-12-29T16:51:31.835658Z","shell.execute_reply":"2024-12-29T16:51:31.838393Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# random seed\nseed_everything(0)\n\n# get data and batchify it\ntrain_loader, test_loader = get_CIFAR10_dataloaders(batch_size=BATCH_SIZE, env=\"colab\")\n\n# choose optimizer and scheduler (if needed)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:51:33.762470Z","iopub.execute_input":"2024-12-29T16:51:33.762775Z","iopub.status.idle":"2024-12-29T16:51:35.072870Z","shell.execute_reply.started":"2024-12-29T16:51:33.762749Z","shell.execute_reply":"2024-12-29T16:51:35.072168Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nPrepare Train Set: ✅\nPrepare Test Set:  ✅\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"exp = comet_ml.Experiment(project_name=\"SSL_Adversarial1\")\nexp.set_name(exp_name)\n\ntrain(model, exp_name, optimizer, NUM_EPOCHS, train_loader, test_loader, is_train_attack_used=\"no\", scheduler=scheduler, exp=exp, env=\"colab\")\n\nexp.end()\n\nprint()\ntest(model, test_loader, env=\"colab\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:51:45.384794Z","iopub.execute_input":"2024-12-29T16:51:45.385139Z","iopub.status.idle":"2024-12-29T16:58:45.073497Z","shell.execute_reply.started":"2024-12-29T16:51:45.385112Z","shell.execute_reply":"2024-12-29T16:58:45.072452Z"}},"outputs":[{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/askoro/ssl-adversarial1/86f5bfad44944f0385bec4ae66a7f2b3\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:22<00:00, 17.74it/s]\n100%|██████████| 79/79 [00:03<00:00, 23.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.9103827179336548, Accuracy: 0.68264\n Validation:\n  Loss: 0.7328914521217346, Accuracy: 0.7403\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 2:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:21<00:00, 18.06it/s]\n100%|██████████| 79/79 [00:03<00:00, 24.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.5527236194038391, Accuracy: 0.80656\n Validation:\n  Loss: 0.7091610786437988, Accuracy: 0.7557\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 3:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:20<00:00, 19.03it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.3557334287261963, Accuracy: 0.87888\n Validation:\n  Loss: 0.6293794045448303, Accuracy: 0.7932\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 4:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:20<00:00, 19.16it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.18254395937919618, Accuracy: 0.94266\n Validation:\n  Loss: 0.6022506805419922, Accuracy: 0.8108\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 5:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:20<00:00, 18.80it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.06it/s]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : SimCLR_SFT\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/askoro/ssl-adversarial1/86f5bfad44944f0385bec4ae66a7f2b3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [196]                          : (3324.70068359375, 150592.5)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train accuracy [5]                  : (0.68264, 0.9776)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss (by steps) [1955]        : (0.03385128080844879, 2.2978591918945312)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss [5]                      : (0.08941236767768859, 0.9103827179336548)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validation accuracy (No Attack) [5] : (0.7403, 0.8183)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validation loss (No Attack) [5]     : (0.5914972339630127, 0.7328914521217346)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : SimCLR_SFT\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (44.73 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.08941236767768859, Accuracy: 0.9776\n Validation:\n  Loss: 0.5914972339630127, Accuracy: 0.8183\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 79/79 [00:03<00:00, 25.27it/s]\n100%|██████████| 79/79 [01:37<00:00,  1.24s/it]\n100%|██████████| 79/79 [01:37<00:00,  1.23s/it]\n100%|██████████| 79/79 [01:36<00:00,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n\nFinal Metrics:\n No Attack:\n   Loss: 0.5914972339630127, Accuracy: 0.8183\n i-FGSM:\n   Loss: 5.551533029174805, Accuracy: 0.2349\n PGD:\n   Loss: 10.571024765014648, Accuracy: 0.011\n DI-FGSM:\n   Loss: 8.680614855957032, Accuracy: 0.0226\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"**SimCLR (Adversarial SFT with i-FGSM):**","metadata":{}},{"cell_type":"code","source":"seed_everything(0)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# initialize SimCLR encoder\nencoder = torchvision.models.resnet.resnet18()\nencoder.fc = torch.nn.Identity()\nencoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nencoder.maxpool = torch.nn.Identity()\ntorch.nn.init.kaiming_normal_(encoder.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\") # initialize conv1 weights the same way as all the other Conv2d weights in ResNet18\n\n# initialize SimCLR\nmodel = SimCLR(encoder=encoder, head_out_dim=256, head_hidden_dim=2048)\nmodel.to(device)\n\nmodel_state_dict = torch.load(\"./weights_SimCLR_Pretrain_epoch10.pth\", map_location=device, weights_only=False)\n\nmodel.load_state_dict(model_state_dict)\n\n# here I take only the backbone of the model and then use it as an encoder in a downstream model \nencoder = model.encoder\n\n# initialize new head\nNUM_CLASSES = 10 # there are 10 classes in CIFAR10\nHIDDEN_SIZE = 512 # output size of SimCLR encoder\n\nhead = torch.nn.Sequential(\n    torch.nn.Linear(HIDDEN_SIZE, 2 * HIDDEN_SIZE),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2 * HIDDEN_SIZE, NUM_CLASSES)\n)\n\n# create downstream model\nmodel = DownstreamModel(encoder=encoder, head=head)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:59:15.869847Z","iopub.execute_input":"2024-12-29T16:59:15.870217Z","iopub.status.idle":"2024-12-29T16:59:16.138928Z","shell.execute_reply.started":"2024-12-29T16:59:15.870190Z","shell.execute_reply":"2024-12-29T16:59:16.138210Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"DownstreamModel(\n  (encoder): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): Identity()\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Identity()\n  )\n  (head): Sequential(\n    (0): Linear(in_features=512, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"comet_ml.login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:59:21.774419Z","iopub.execute_input":"2024-12-29T16:59:21.774693Z","iopub.status.idle":"2024-12-29T16:59:21.979922Z","shell.execute_reply.started":"2024-12-29T16:59:21.774672Z","shell.execute_reply":"2024-12-29T16:59:21.979335Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# choose device for computing\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:59:23.541138Z","iopub.execute_input":"2024-12-29T16:59:23.541466Z","iopub.status.idle":"2024-12-29T16:59:23.545443Z","shell.execute_reply.started":"2024-12-29T16:59:23.541438Z","shell.execute_reply":"2024-12-29T16:59:23.544517Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"NUM_EPOCHS = 5\nBATCH_SIZE = 128\nexp_name = \"SimCLR_Adversarial_SFT_BIM\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:59:46.865824Z","iopub.execute_input":"2024-12-29T16:59:46.866178Z","iopub.status.idle":"2024-12-29T16:59:46.869893Z","shell.execute_reply.started":"2024-12-29T16:59:46.866149Z","shell.execute_reply":"2024-12-29T16:59:46.869024Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# random seed\nseed_everything(0)\n\n# get data and batchify it\ntrain_loader, test_loader = get_CIFAR10_dataloaders(batch_size=BATCH_SIZE, env=\"colab\")\n\n# choose optimizer and scheduler (if needed)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:59:49.130973Z","iopub.execute_input":"2024-12-29T16:59:49.131250Z","iopub.status.idle":"2024-12-29T16:59:50.448595Z","shell.execute_reply.started":"2024-12-29T16:59:49.131229Z","shell.execute_reply":"2024-12-29T16:59:50.447840Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nPrepare Train Set: ✅\nPrepare Test Set:  ✅\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"exp = comet_ml.Experiment(project_name=\"SSL_Adversarial1\")\nexp.set_name(exp_name)\n\ntrain(model, exp_name, optimizer, NUM_EPOCHS, train_loader, test_loader, is_train_attack_used=\"BIM\", scheduler=scheduler, exp=exp, env=\"colab\")\n\nexp.end()\n\nprint()\ntest(model, test_loader, env=\"colab\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:00:39.394015Z","iopub.execute_input":"2024-12-29T17:00:39.394322Z","iopub.status.idle":"2024-12-29T17:27:12.624173Z","shell.execute_reply.started":"2024-12-29T17:00:39.394302Z","shell.execute_reply":"2024-12-29T17:27:12.623293Z"}},"outputs":[{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/askoro/ssl-adversarial1/4bf1baee57d9455c85f0fc820edb8469\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:15<00:00,  1.53it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 1.0919768834114074, Accuracy: 0.60842\n Validation:\n  Loss: 0.7880367339134217, Accuracy: 0.716\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 2:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:14<00:00,  1.54it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.7488188358497619, Accuracy: 0.73032\n Validation:\n  Loss: 0.6920432047843933, Accuracy: 0.756\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 3:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:14<00:00,  1.54it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.5665773409080506, Accuracy: 0.79722\n Validation:\n  Loss: 0.6476041121959686, Accuracy: 0.7721\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 4:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:14<00:00,  1.53it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.39992755230903626, Accuracy: 0.86078\n Validation:\n  Loss: 0.5704483959197998, Accuracy: 0.8044\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 5:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:14<00:00,  1.53it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.67it/s]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : SimCLR_Adversarial_SFT_BIM\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/askoro/ssl-adversarial1/4bf1baee57d9455c85f0fc820edb8469\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [196]                          : (10466.81640625, 152427.0)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train accuracy [5]                  : (0.60842, 0.90786)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss (by steps) [1955]        : (0.15724311769008636, 2.3258514404296875)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss [5]                      : (0.2816477269935608, 1.0919768834114074)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validation accuracy (No Attack) [5] : (0.716, 0.817)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validation loss (No Attack) [5]     : (0.5391895300388336, 0.7880367339134217)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : SimCLR_Adversarial_SFT_BIM\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (44.73 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.2816477269935608, Accuracy: 0.90786\n Validation:\n  Loss: 0.5391895300388336, Accuracy: 0.817\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 40.50 MB/44.73 MB\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 79/79 [00:03<00:00, 25.77it/s]\n100%|██████████| 79/79 [01:37<00:00,  1.24s/it]\n100%|██████████| 79/79 [01:36<00:00,  1.22s/it]\n100%|██████████| 79/79 [01:36<00:00,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n\nFinal Metrics:\n No Attack:\n   Loss: 0.5391895300388336, Accuracy: 0.817\n i-FGSM:\n   Loss: 0.9786480871200561, Accuracy: 0.6808\n PGD:\n   Loss: 3.3085753410339356, Accuracy: 0.1516\n DI-FGSM:\n   Loss: 3.1250150234222414, Accuracy: 0.1745\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"**SimCLR (Adversarial SFT with PGD):**","metadata":{}},{"cell_type":"code","source":"seed_everything(0)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# initialize SimCLR encoder\nencoder = torchvision.models.resnet.resnet18()\nencoder.fc = torch.nn.Identity()\nencoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nencoder.maxpool = torch.nn.Identity()\ntorch.nn.init.kaiming_normal_(encoder.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\") # initialize conv1 weights the same way as all the other Conv2d weights in ResNet18\n\n# initialize SimCLR\nmodel = SimCLR(encoder=encoder, head_out_dim=256, head_hidden_dim=2048)\nmodel.to(device)\n\nmodel_state_dict = torch.load(\"./weights_SimCLR_Pretrain_epoch10.pth\", map_location=device, weights_only=False)\n\nmodel.load_state_dict(model_state_dict)\n\n# here I take only the backbone of the model and then use it as an encoder in a downstream model \nencoder = model.encoder\n\n# initialize new head\nNUM_CLASSES = 10 # there are 10 classes in CIFAR10\nHIDDEN_SIZE = 512 # output size of SimCLR encoder\n\nhead = torch.nn.Sequential(\n    torch.nn.Linear(HIDDEN_SIZE, 2 * HIDDEN_SIZE),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2 * HIDDEN_SIZE, NUM_CLASSES)\n)\n\n# create downstream model\nmodel = DownstreamModel(encoder=encoder, head=head)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:41:10.173020Z","iopub.execute_input":"2024-12-29T22:41:10.173586Z","iopub.status.idle":"2024-12-29T22:41:10.737253Z","shell.execute_reply.started":"2024-12-29T22:41:10.173559Z","shell.execute_reply":"2024-12-29T22:41:10.736441Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DownstreamModel(\n  (encoder): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): Identity()\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Identity()\n  )\n  (head): Sequential(\n    (0): Linear(in_features=512, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"comet_ml.login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:43:05.025130Z","iopub.execute_input":"2024-12-29T22:43:05.025425Z","iopub.status.idle":"2024-12-29T22:43:05.208168Z","shell.execute_reply.started":"2024-12-29T22:43:05.025404Z","shell.execute_reply":"2024-12-29T22:43:05.207523Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# choose device for computing\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:43:09.125193Z","iopub.execute_input":"2024-12-29T22:43:09.125552Z","iopub.status.idle":"2024-12-29T22:43:09.129369Z","shell.execute_reply.started":"2024-12-29T22:43:09.125525Z","shell.execute_reply":"2024-12-29T22:43:09.128410Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"NUM_EPOCHS = 5\nBATCH_SIZE = 128\nexp_name = \"SimCLR_Adversarial_SFT_PGD\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:46:10.887267Z","iopub.execute_input":"2024-12-29T22:46:10.887586Z","iopub.status.idle":"2024-12-29T22:46:10.891408Z","shell.execute_reply.started":"2024-12-29T22:46:10.887565Z","shell.execute_reply":"2024-12-29T22:46:10.890491Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# random seed\nseed_everything(0)\n\n# get data and batchify it\ntrain_loader, test_loader = get_CIFAR10_dataloaders(batch_size=BATCH_SIZE, env=\"colab\")\n\n# choose optimizer and scheduler (if needed)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:47:43.079264Z","iopub.execute_input":"2024-12-29T22:47:43.079589Z","iopub.status.idle":"2024-12-29T22:47:48.234138Z","shell.execute_reply.started":"2024-12-29T22:47:43.079567Z","shell.execute_reply":"2024-12-29T22:47:48.233227Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:02<00:00, 81050869.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./cifar-10-python.tar.gz to ./\nPrepare Train Set: ✅\nPrepare Test Set:  ✅\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"exp = comet_ml.Experiment(project_name=\"SSL_Adversarial1\")\nexp.set_name(exp_name)\n\ntrain(model, exp_name, optimizer, NUM_EPOCHS, train_loader, test_loader, is_train_attack_used=\"PGD\", scheduler=scheduler, exp=exp, env=\"colab\")\n\nexp.end()\n\nprint()\ntest(model, test_loader, env=\"colab\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:49:56.728816Z","iopub.execute_input":"2024-12-29T22:49:56.729267Z","iopub.status.idle":"2024-12-29T23:16:26.333562Z","shell.execute_reply.started":"2024-12-29T22:49:56.729217Z","shell.execute_reply":"2024-12-29T23:16:26.331977Z"}},"outputs":[{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/askoro/ssl-adversarial1/626eb124f1d14efd9e1291e5daa361c0\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1:\n\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/391 [00:00<?, ?it/s]\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n100%|██████████| 391/391 [04:16<00:00,  1.52it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 1.512427154006958, Accuracy: 0.44314\n Validation:\n  Loss: 4.736591479492187, Accuracy: 0.2384\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 2:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:14<00:00,  1.54it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 1.255387674179077, Accuracy: 0.5371\n Validation:\n  Loss: 2.9791353565216063, Accuracy: 0.392\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 3:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:13<00:00,  1.54it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 1.1112176685333253, Accuracy: 0.59042\n Validation:\n  Loss: 3.3777536708831786, Accuracy: 0.3925\n🎉🎉🎉 New Best Validation Accuracy 🎉🎉🎉\nSave State of the Best Model: ✅\nDelete State File of the Previous Best Model: ✅\n-----------------------------------------------------------------\n\nEpoch 4:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:14<00:00,  1.54it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.9606604817199706, Accuracy: 0.64708\n Validation:\n  Loss: 3.341874614715576, Accuracy: 0.3871\n-----------------------------------------------------------------\n\nEpoch 5:\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [04:14<00:00,  1.54it/s]\n100%|██████████| 79/79 [00:03<00:00, 25.60it/s]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : SimCLR_Adversarial_SFT_PGD\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/askoro/ssl-adversarial1/626eb124f1d14efd9e1291e5daa361c0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [196]                          : (41399.59375, 153568.5)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train accuracy [5]                  : (0.44314, 0.69908)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss (by steps) [1955]        : (0.6170915365219116, 2.3432693481445312)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss [5]                      : (0.8292864834976196, 1.512427154006958)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validation accuracy (No Attack) [5] : (0.2384, 0.3925)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validation loss (No Attack) [5]     : (2.9791353565216063, 4.736591479492187)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : SimCLR_Adversarial_SFT_PGD\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (44.73 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","output_type":"stream"},{"name":"stdout","text":"\n\n Train:\n  Loss: 0.8292864834976196, Accuracy: 0.69908\n Validation:\n  Loss: 3.875953694152832, Accuracy: 0.3524\n-----------------------------------------------------------------\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 79/79 [00:03<00:00, 25.32it/s]\n100%|██████████| 79/79 [01:37<00:00,  1.23s/it]\n100%|██████████| 79/79 [01:36<00:00,  1.22s/it]\n100%|██████████| 79/79 [01:37<00:00,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n\nFinal Metrics:\n No Attack:\n   Loss: 3.875953694152832, Accuracy: 0.3524\n i-FGSM:\n   Loss: 4.3787047439575195, Accuracy: 0.2859\n PGD:\n   Loss: 1.6716163145065308, Accuracy: 0.4218\n DI-FGSM:\n   Loss: 1.5476438034057618, Accuracy: 0.4613\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23}]}